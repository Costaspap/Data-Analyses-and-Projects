{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import the data and split on a 90-10 basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading the data (Digits)\n",
    "train = np.loadtxt('train.csv',skiprows = 1,delimiter = ',')\n",
    "\n",
    "train, test = train_test_split(train,train_size = 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the labels and one-hot encoding them, I will convert the data to the necessary shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 37800\n",
      "number of test examples = 4200\n",
      "X_train shape: (37800, 28, 28, 1)\n",
      "Y_train shape: (37800, 10)\n",
      "X_test shape: (4200, 28, 28, 1)\n",
      "Y_test shape: (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train = train[:,1:].copy()\n",
    "Y_train = train[:,0].reshape(train.shape[0],1).copy()\n",
    "X_test = test[:,1:].copy()\n",
    "Y_test = test[:,0].reshape(test.shape[0],1).copy()\n",
    "X_train = (X_train/255.).reshape(X_train.shape[0],28,28,1).copy()\n",
    "X_test = (X_test/255.).reshape(X_test.shape[0],28,28,1).copy()\n",
    "\n",
    "oh = OneHotEncoder(sparse = False)\n",
    "Y_train = oh.fit_transform(X=Y_train.reshape(X_train.shape[0],1))\n",
    "Y_test = oh.fit_transform(X=Y_test.reshape(X_test.shape[0],1))\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DigitRecognizer(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Digit Recognizer.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Layer 1\n",
    "    X = Conv2D(64, (5, 5), name = 'conv0', activation = 'relu')(X)\n",
    "    X = Conv2D(64, (3, 3), name = 'conv1', activation = 'relu', padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Dropout(rate = 0.4)(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "    \n",
    "    # Layer 2\n",
    "    X = Conv2D(32, (2, 2), name = 'conv2', activation = 'relu', padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Dropout(rate = 0.3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    \n",
    "    # Layer 3\n",
    "    X = Conv2D(128, (2, 2), name = 'conv3', activation = 'relu', padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = Dropout(rate = 0.3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n",
    "    \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = Dense(1024, activation='relu', name='fc1')(X)\n",
    "    X = Dropout(rate = 0.3)(X)\n",
    "    \n",
    "    X = Dense(10, activation='softmax', name='fc2')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='DigitRecognizer')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create and view the structure of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 34, 34, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 30, 30, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 15, 15, 32)        8224      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 7, 7, 128)         16512     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,255,146\n",
      "Trainable params: 1,254,698\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DigitRecognizer((28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model incorporates a large number of parameters, so I added dropout to avoid overfitting. Lets train it for 8 epochs, evaluating the test set in each one to monitor both performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0321 - acc: 0.9898\n",
      "37800/37800 [==============================] - 4s 110us/step\n",
      "4200/4200 [==============================] - 0s 111us/step\n",
      "\n",
      "Epoch 1\n",
      "--------------------------\n",
      "Train Accuracy = 99.25%\n",
      "Validation Accuracy = 98.76%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0319 - acc: 0.9897\n",
      "37800/37800 [==============================] - 4s 114us/step\n",
      "4200/4200 [==============================] - 0s 111us/step\n",
      "\n",
      "Epoch 2\n",
      "--------------------------\n",
      "Train Accuracy = 99.59%\n",
      "Validation Accuracy = 99.19%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0278 - acc: 0.9911\n",
      "37800/37800 [==============================] - 4s 110us/step\n",
      "4200/4200 [==============================] - 0s 109us/step\n",
      "\n",
      "Epoch 3\n",
      "--------------------------\n",
      "Train Accuracy = 99.46%\n",
      "Validation Accuracy = 99.05%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0276 - acc: 0.9913\n",
      "37800/37800 [==============================] - 4s 112us/step\n",
      "4200/4200 [==============================] - 0s 111us/step\n",
      "\n",
      "Epoch 4\n",
      "--------------------------\n",
      "Train Accuracy = 99.67%\n",
      "Validation Accuracy = 99.31%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0238 - acc: 0.9923\n",
      "37800/37800 [==============================] - 4s 111us/step\n",
      "4200/4200 [==============================] - 0s 111us/step\n",
      "\n",
      "Epoch 5\n",
      "--------------------------\n",
      "Train Accuracy = 99.74%\n",
      "Validation Accuracy = 99.12%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0217 - acc: 0.9923\n",
      "37800/37800 [==============================] - 4s 112us/step\n",
      "4200/4200 [==============================] - 0s 112us/step\n",
      "\n",
      "Epoch 6\n",
      "--------------------------\n",
      "Train Accuracy = 99.75%\n",
      "Validation Accuracy = 99.19%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0232 - acc: 0.9922\n",
      "37800/37800 [==============================] - 4s 112us/step\n",
      "4200/4200 [==============================] - 0s 113us/step\n",
      "\n",
      "Epoch 7\n",
      "--------------------------\n",
      "Train Accuracy = 99.76%\n",
      "Validation Accuracy = 99.26%\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.0209 - acc: 0.9926\n",
      "37800/37800 [==============================] - 4s 112us/step\n",
      "4200/4200 [==============================] - 0s 112us/step\n",
      "\n",
      "Epoch 8\n",
      "--------------------------\n",
      "Train Accuracy = 99.7%\n",
      "Validation Accuracy = 99.1%\n",
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,8):\n",
    "    model.fit(x = X_train, y = Y_train, epochs = 1, batch_size = 512)\n",
    "    preds_train = model.evaluate(x = X_train, y = Y_train)\n",
    "    preds_test = model.evaluate(x = X_test, y = Y_test)\n",
    "    \n",
    "    print()\n",
    "    print('Epoch ' + str(epoch + 1))\n",
    "    print('--------------------------')\n",
    "    print (\"Train Accuracy = \" + str(round(preds_train[1]*100,2))+'%')\n",
    "    print (\"Validation Accuracy = \" + str(round(preds_test[1]*100,2))+'%')\n",
    "    print('--------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I basically trained the model for 16 epochs since I ran the cell 2 times. Its obvious that the accuracy has hit the top so no point training further. But that can also mean that it is overfitting. Lets test by submitting it on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = np.loadtxt('test.csv',skiprows = 1,delimiter = ',')\n",
    "final = final.reshape(final.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final = (final/255.).reshape(final.shape[0],28,28,1).copy()\n",
    "predictions = model.predict(X_final)\n",
    "predictions = np.round(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new =predictions@np.array([0,1,2,3,4,5,6,7,8,9]).reshape(10,1)\n",
    "prd = pd.Series(new.reshape(X_final.shape[0],))\n",
    "prd = prd.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.concat([pd.Series(prd.index),pd.Series(prd.values)],axis = 1)\n",
    "output.columns = ['ImageId','Label']\n",
    "output['ImageId'] += 1\n",
    "output.to_csv('keras.csv',sep = ',', header = ['ImageId','Label'], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Your submission scored 0.98942, which is an improvement of your previous score of 0.98571. Great job!\". Well not that great if one considers that the best model out there achieves 99,97% accuracy. But its a start. Lets work on improving it further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
